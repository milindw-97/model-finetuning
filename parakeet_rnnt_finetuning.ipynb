{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-Tuning Parakeet RNNT 1.1B Multilingual\n",
        "\n",
        "This notebook provides a complete pipeline for fine-tuning NVIDIA's `parakeet-rnnt-1.1b-multilingual` model using the NeMo framework.\n",
        "\n",
        "**Reference:** [NeMo Multilang ASR Tutorial](https://github.com/NVIDIA-NeMo/NeMo/blob/main/tutorials/asr/Multilang_ASR.ipynb)\n",
        "\n",
        "## Features\n",
        "- Load pre-trained Parakeet RNNT 1.1B Multilingual model\n",
        "- Prepare datasets with NeMo manifest format\n",
        "- Configure model for fine-tuning with best practices\n",
        "- Train with PyTorch Lightning\n",
        "- Evaluate and run inference\n",
        "\n",
        "## Requirements\n",
        "- NVIDIA GPU with 16GB+ VRAM (recommended)\n",
        "- Python 3.8+\n",
        "- CUDA 11.8+\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect environment\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"üåê Running on Google Colab\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print(\"üíª Running locally\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "# IMPORTANT: After running this cell, RESTART THE RUNTIME before continuing!\n",
        "\n",
        "INSTALL_PACKAGES = True  # Set to False if already installed\n",
        "\n",
        "if INSTALL_PACKAGES:\n",
        "    print(\"üì¶ Installing NeMo and dependencies...\")\n",
        "    print(\"This may take 5-10 minutes...\\n\")\n",
        "    \n",
        "    # Core dependencies\n",
        "    !pip install -q Cython packaging\n",
        "    \n",
        "    # Install NeMo toolkit with ASR support\n",
        "    # Option 1: From PyPI (stable)\n",
        "    !pip install -q 'nemo_toolkit[asr]'\n",
        "    \n",
        "    # Option 2: From source (latest features - uncomment if needed)\n",
        "    # !pip install -q git+https://github.com/NVIDIA/NeMo.git#egg=nemo_toolkit[asr]\n",
        "    \n",
        "    # Additional dependencies\n",
        "    !pip install -q soundfile librosa datasets jiwer\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚ö†Ô∏è  IMPORTANT: Please restart the runtime now!\")\n",
        "    print(\"   Go to: Runtime -> Restart runtime\")\n",
        "    print(\"   Then continue from the next cell.\")\n",
        "    print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Union, Any\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# NeMo imports\n",
        "import nemo\n",
        "import nemo.collections.asr as nemo_asr\n",
        "from nemo.utils.exp_manager import exp_manager\n",
        "from omegaconf import OmegaConf, open_dict\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Check versions and GPU\n",
        "print(f\"‚úì PyTorch: {torch.__version__}\")\n",
        "print(f\"‚úì NeMo: {nemo.__version__}\")\n",
        "print(f\"‚úì PyTorch Lightning: {pl.__version__}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"\\nüéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"   CUDA: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No GPU detected! Training will be very slow.\")\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Modify the configuration below based on your dataset and hardware.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataConfig:\n",
        "    \"\"\"Dataset configuration.\"\"\"\n",
        "    # Manifest paths (NeMo JSON Lines format)\n",
        "    train_manifest: str = \"./data/train_manifest.json\"\n",
        "    val_manifest: str = \"./data/val_manifest.json\"\n",
        "    test_manifest: Optional[str] = \"./data/test_manifest.json\"\n",
        "    \n",
        "    # Audio settings\n",
        "    sample_rate: int = 16000\n",
        "    max_duration: float = 20.0  # seconds\n",
        "    min_duration: float = 0.1   # seconds\n",
        "    \n",
        "    # Batch settings\n",
        "    train_batch_size: int = 16\n",
        "    val_batch_size: int = 16\n",
        "    num_workers: int = 4\n",
        "    \n",
        "    # Spec Augmentation\n",
        "    enable_spec_augment: bool = True\n",
        "    freq_masks: int = 2\n",
        "    time_masks: int = 10\n",
        "    freq_width: int = 27\n",
        "    time_width: float = 0.05\n",
        "\n",
        "\n",
        "@dataclass \n",
        "class TrainingConfig:\n",
        "    \"\"\"Training configuration.\"\"\"\n",
        "    # Model\n",
        "    pretrained_model: str = \"nvidia/parakeet-rnnt-1.1b-multilingual\"\n",
        "    \n",
        "    # Output\n",
        "    output_dir: str = \"./outputs/parakeet-rnnt-finetuned\"\n",
        "    exp_name: str = \"parakeet_rnnt_finetune\"\n",
        "    \n",
        "    # Training hyperparameters\n",
        "    max_epochs: int = 50\n",
        "    learning_rate: float = 1e-4\n",
        "    min_lr: float = 1e-6\n",
        "    warmup_steps: int = 1000\n",
        "    weight_decay: float = 1e-3\n",
        "    \n",
        "    # Optimizer & Scheduler\n",
        "    optimizer: str = \"adamw\"\n",
        "    scheduler: str = \"CosineAnnealing\"\n",
        "    \n",
        "    # Precision & Gradient\n",
        "    precision: str = \"16-mixed\"\n",
        "    grad_clip: float = 1.0\n",
        "    accumulate_grad_batches: int = 1\n",
        "    \n",
        "    # Checkpointing\n",
        "    save_top_k: int = 3\n",
        "    checkpoint_every_n_epochs: int = 1\n",
        "    \n",
        "    # Early stopping\n",
        "    early_stop_patience: int = 10\n",
        "    \n",
        "    # Encoder freezing\n",
        "    freeze_encoder: bool = False\n",
        "    \n",
        "    # Device\n",
        "    devices: int = 1\n",
        "    accelerator: str = \"gpu\"\n",
        "    \n",
        "    # Logging\n",
        "    log_every_n_steps: int = 50\n",
        "    \n",
        "    # Resume\n",
        "    resume_from_checkpoint: Optional[str] = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# üìù CONFIGURE YOUR TRAINING HERE\n",
        "# ============================================================================\n",
        "\n",
        "DATA_CONFIG = DataConfig(\n",
        "    # üìÅ Your manifest file paths\n",
        "    train_manifest=\"./data/train_manifest.json\",\n",
        "    val_manifest=\"./data/val_manifest.json\",\n",
        "    test_manifest=\"./data/test_manifest.json\",  # Optional\n",
        "    \n",
        "    # üîä Audio settings\n",
        "    sample_rate=16000,\n",
        "    max_duration=20.0,  # Filter out audio longer than this\n",
        "    min_duration=0.5,   # Filter out audio shorter than this\n",
        "    \n",
        "    # üì¶ Batch settings (adjust based on GPU memory)\n",
        "    train_batch_size=8,   # Reduce if OOM\n",
        "    val_batch_size=8,\n",
        "    num_workers=4,\n",
        "    \n",
        "    # üé≠ Data augmentation\n",
        "    enable_spec_augment=True,\n",
        ")\n",
        "\n",
        "TRAINING_CONFIG = TrainingConfig(\n",
        "    # ü§ñ Pre-trained model\n",
        "    pretrained_model=\"nvidia/parakeet-rnnt-1.1b-multilingual\",\n",
        "    \n",
        "    # üìÇ Output directory\n",
        "    output_dir=\"./outputs/parakeet-rnnt-finetuned\",\n",
        "    exp_name=\"parakeet_finetune\",\n",
        "    \n",
        "    # üéØ Training hyperparameters\n",
        "    max_epochs=50,\n",
        "    learning_rate=1e-4,    # Lower for small datasets (5e-5)\n",
        "    warmup_steps=1000,\n",
        "    weight_decay=1e-3,\n",
        "    \n",
        "    # ‚ö° Performance\n",
        "    precision=\"16-mixed\",  # Use bf16-mixed if your GPU supports it\n",
        "    accumulate_grad_batches=2,  # Increase for effective larger batch size\n",
        "    \n",
        "    # üßä Encoder freezing (recommended for small datasets)\n",
        "    freeze_encoder=False,  # Set True if dataset < 10 hours\n",
        "    \n",
        "    # ‚è±Ô∏è Early stopping\n",
        "    early_stop_patience=10,\n",
        "    \n",
        "    # üíæ Checkpointing\n",
        "    save_top_k=3,\n",
        ")\n",
        "\n",
        "# Colab-specific paths\n",
        "if IN_COLAB:\n",
        "    DATA_CONFIG.train_manifest = \"/content/drive/MyDrive/data/train_manifest.json\"\n",
        "    DATA_CONFIG.val_manifest = \"/content/drive/MyDrive/data/val_manifest.json\"\n",
        "    DATA_CONFIG.test_manifest = \"/content/drive/MyDrive/data/test_manifest.json\"\n",
        "    TRAINING_CONFIG.output_dir = \"/content/drive/MyDrive/outputs/parakeet-finetuned\"\n",
        "\n",
        "print(\"Configuration loaded!\")\n",
        "print(f\"  Model: {TRAINING_CONFIG.pretrained_model}\")\n",
        "print(f\"  Train manifest: {DATA_CONFIG.train_manifest}\")\n",
        "print(f\"  Val manifest: {DATA_CONFIG.val_manifest}\")\n",
        "print(f\"  Output dir: {TRAINING_CONFIG.output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Preparation\n",
        "\n",
        "NeMo uses JSON Lines manifest files where each line is a JSON object:\n",
        "\n",
        "```json\n",
        "{\"audio_filepath\": \"/path/to/audio.wav\", \"text\": \"transcription\", \"duration\": 2.5, \"lang\": \"en\"}\n",
        "```\n",
        "\n",
        "**Required fields:**\n",
        "- `audio_filepath`: Path to audio file\n",
        "- `text`: Transcription text\n",
        "- `duration`: Audio duration in seconds\n",
        "\n",
        "**Optional fields:**\n",
        "- `lang`: Language code (for multilingual models)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "\n",
        "def create_manifest_from_folder(\n",
        "    audio_dir: str,\n",
        "    output_manifest: str,\n",
        "    transcriptions: Dict[str, str] = None,\n",
        "    transcription_file: str = None,\n",
        "    language: str = \"en\",\n",
        "    audio_extensions: List[str] = [\".wav\", \".flac\", \".mp3\", \".ogg\"]\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Create NeMo manifest from a folder of audio files.\n",
        "    \n",
        "    Args:\n",
        "        audio_dir: Directory containing audio files\n",
        "        output_manifest: Path for output manifest file\n",
        "        transcriptions: Dict mapping filename -> transcription\n",
        "        transcription_file: JSON file with {filename: transcription} mapping\n",
        "        language: Language code for all samples\n",
        "        audio_extensions: Audio file extensions to include\n",
        "    \n",
        "    Returns:\n",
        "        Path to created manifest\n",
        "    \"\"\"\n",
        "    audio_dir = Path(audio_dir)\n",
        "    output_manifest = Path(output_manifest)\n",
        "    output_manifest.parent.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Load transcriptions\n",
        "    if transcription_file and Path(transcription_file).exists():\n",
        "        with open(transcription_file, 'r', encoding='utf-8') as f:\n",
        "            transcriptions = json.load(f)\n",
        "    elif transcriptions is None:\n",
        "        transcriptions = {}\n",
        "    \n",
        "    entries = []\n",
        "    skipped = 0\n",
        "    \n",
        "    for ext in audio_extensions:\n",
        "        for audio_path in audio_dir.rglob(f\"*{ext}\"):\n",
        "            try:\n",
        "                # Get duration\n",
        "                info = sf.info(str(audio_path))\n",
        "                duration = info.duration\n",
        "                \n",
        "                # Get transcription\n",
        "                filename = audio_path.name\n",
        "                text = transcriptions.get(filename, transcriptions.get(str(audio_path), \"\"))\n",
        "                \n",
        "                if not text:\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "                \n",
        "                entry = {\n",
        "                    \"audio_filepath\": str(audio_path.absolute()),\n",
        "                    \"text\": text.strip(),\n",
        "                    \"duration\": round(duration, 3),\n",
        "                    \"lang\": language\n",
        "                }\n",
        "                entries.append(entry)\n",
        "                \n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error processing {audio_path}: {e}\")\n",
        "                skipped += 1\n",
        "    \n",
        "    # Write manifest\n",
        "    with open(output_manifest, 'w', encoding='utf-8') as f:\n",
        "        for entry in entries:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
        "    \n",
        "    print(f\"‚úì Created manifest: {output_manifest}\")\n",
        "    print(f\"  Samples: {len(entries)}\")\n",
        "    print(f\"  Skipped: {skipped}\")\n",
        "    \n",
        "    return str(output_manifest)\n",
        "\n",
        "\n",
        "def create_manifest_from_huggingface(\n",
        "    dataset_name: str,\n",
        "    output_manifest: str,\n",
        "    audio_output_dir: str,\n",
        "    split: str = \"train\",\n",
        "    config_name: str = None,\n",
        "    audio_column: str = \"audio\",\n",
        "    text_column: str = \"sentence\",\n",
        "    language: str = \"en\",\n",
        "    max_samples: int = None\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Create NeMo manifest from a HuggingFace dataset.\n",
        "    \"\"\"\n",
        "    from datasets import load_dataset\n",
        "    \n",
        "    output_manifest = Path(output_manifest)\n",
        "    audio_output_dir = Path(audio_output_dir)\n",
        "    output_manifest.parent.mkdir(parents=True, exist_ok=True)\n",
        "    audio_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    print(f\"Loading dataset: {dataset_name}...\")\n",
        "    \n",
        "    if config_name:\n",
        "        dataset = load_dataset(dataset_name, config_name, split=split, trust_remote_code=True)\n",
        "    else:\n",
        "        dataset = load_dataset(dataset_name, split=split, trust_remote_code=True)\n",
        "    \n",
        "    if max_samples:\n",
        "        dataset = dataset.select(range(min(len(dataset), max_samples)))\n",
        "    \n",
        "    print(f\"Processing {len(dataset)} samples...\")\n",
        "    \n",
        "    entries = []\n",
        "    \n",
        "    for idx, sample in enumerate(dataset):\n",
        "        try:\n",
        "            audio = sample[audio_column]\n",
        "            text = sample[text_column]\n",
        "            \n",
        "            if isinstance(audio, dict):\n",
        "                array = audio['array']\n",
        "                sr = audio.get('sampling_rate', 16000)\n",
        "                \n",
        "                # Save audio file\n",
        "                audio_path = audio_output_dir / f\"audio_{idx:06d}.wav\"\n",
        "                sf.write(str(audio_path), array, sr)\n",
        "                \n",
        "                duration = len(array) / sr\n",
        "            else:\n",
        "                audio_path = Path(audio)\n",
        "                info = sf.info(str(audio_path))\n",
        "                duration = info.duration\n",
        "            \n",
        "            entry = {\n",
        "                \"audio_filepath\": str(audio_path.absolute()),\n",
        "                \"text\": text.strip(),\n",
        "                \"duration\": round(duration, 3),\n",
        "                \"lang\": language\n",
        "            }\n",
        "            entries.append(entry)\n",
        "            \n",
        "            if (idx + 1) % 1000 == 0:\n",
        "                print(f\"  Processed {idx + 1}/{len(dataset)} samples\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error processing sample {idx}: {e}\")\n",
        "    \n",
        "    # Write manifest\n",
        "    with open(output_manifest, 'w', encoding='utf-8') as f:\n",
        "        for entry in entries:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
        "    \n",
        "    print(f\"\\n‚úì Created manifest: {output_manifest}\")\n",
        "    print(f\"  Samples: {len(entries)}\")\n",
        "    \n",
        "    return str(output_manifest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_manifest(manifest_path: str) -> Dict[str, Any]:\n",
        "    \"\"\"Validate manifest and return statistics.\"\"\"\n",
        "    manifest_path = Path(manifest_path)\n",
        "    \n",
        "    if not manifest_path.exists():\n",
        "        raise FileNotFoundError(f\"Manifest not found: {manifest_path}\")\n",
        "    \n",
        "    stats = {\n",
        "        \"total_samples\": 0,\n",
        "        \"total_duration_hours\": 0,\n",
        "        \"missing_files\": 0,\n",
        "        \"languages\": {},\n",
        "        \"duration_range\": {\"min\": float('inf'), \"max\": 0}\n",
        "    }\n",
        "    \n",
        "    with open(manifest_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                entry = json.loads(line.strip())\n",
        "                \n",
        "                stats[\"total_samples\"] += 1\n",
        "                \n",
        "                duration = entry.get(\"duration\", 0)\n",
        "                stats[\"total_duration_hours\"] += duration / 3600\n",
        "                stats[\"duration_range\"][\"min\"] = min(stats[\"duration_range\"][\"min\"], duration)\n",
        "                stats[\"duration_range\"][\"max\"] = max(stats[\"duration_range\"][\"max\"], duration)\n",
        "                \n",
        "                lang = entry.get(\"lang\", \"unknown\")\n",
        "                stats[\"languages\"][lang] = stats[\"languages\"].get(lang, 0) + 1\n",
        "                \n",
        "                audio_path = entry.get(\"audio_filepath\")\n",
        "                if audio_path and not Path(audio_path).exists():\n",
        "                    stats[\"missing_files\"] += 1\n",
        "                    \n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "    \n",
        "    if stats[\"duration_range\"][\"min\"] == float('inf'):\n",
        "        stats[\"duration_range\"][\"min\"] = 0\n",
        "    \n",
        "    return stats\n",
        "\n",
        "\n",
        "def print_manifest_stats(manifest_path: str):\n",
        "    \"\"\"Print manifest statistics.\"\"\"\n",
        "    try:\n",
        "        stats = validate_manifest(manifest_path)\n",
        "        print(f\"\\nüìä Manifest: {Path(manifest_path).name}\")\n",
        "        print(f\"   Samples: {stats['total_samples']:,}\")\n",
        "        print(f\"   Duration: {stats['total_duration_hours']:.2f} hours\")\n",
        "        print(f\"   Range: {stats['duration_range']['min']:.1f}s - {stats['duration_range']['max']:.1f}s\")\n",
        "        print(f\"   Languages: {stats['languages']}\")\n",
        "        if stats['missing_files'] > 0:\n",
        "            print(f\"   ‚ö†Ô∏è  Missing files: {stats['missing_files']}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\n‚ùå Manifest not found: {manifest_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Create manifests from HuggingFace dataset\n",
        "# Uncomment and modify as needed\n",
        "\n",
        "CREATE_FROM_HUGGINGFACE = False  # Set to True to create manifests\n",
        "\n",
        "if CREATE_FROM_HUGGINGFACE:\n",
        "    # Download and prepare Common Voice English subset\n",
        "    create_manifest_from_huggingface(\n",
        "        dataset_name=\"mozilla-foundation/common_voice_11_0\",\n",
        "        output_manifest=\"./data/train_manifest.json\",\n",
        "        audio_output_dir=\"./data/audio/train\",\n",
        "        split=\"train\",\n",
        "        config_name=\"en\",  # Language code\n",
        "        audio_column=\"audio\",\n",
        "        text_column=\"sentence\",\n",
        "        language=\"en\",\n",
        "        max_samples=5000  # Limit for testing\n",
        "    )\n",
        "    \n",
        "    create_manifest_from_huggingface(\n",
        "        dataset_name=\"mozilla-foundation/common_voice_11_0\",\n",
        "        output_manifest=\"./data/val_manifest.json\",\n",
        "        audio_output_dir=\"./data/audio/val\",\n",
        "        split=\"validation\",\n",
        "        config_name=\"en\",\n",
        "        audio_column=\"audio\",\n",
        "        text_column=\"sentence\",\n",
        "        language=\"en\",\n",
        "        max_samples=500\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate your manifests\n",
        "print_manifest_stats(DATA_CONFIG.train_manifest)\n",
        "print_manifest_stats(DATA_CONFIG.val_manifest)\n",
        "\n",
        "if DATA_CONFIG.test_manifest:\n",
        "    print_manifest_stats(DATA_CONFIG.test_manifest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Pre-trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-trained Parakeet RNNT model\n",
        "print(f\"Loading model: {TRAINING_CONFIG.pretrained_model}\")\n",
        "print(\"This may take a few minutes for initial download...\\n\")\n",
        "\n",
        "model_name = TRAINING_CONFIG.pretrained_model.replace('nvidia/', '')\n",
        "\n",
        "try:\n",
        "    model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(model_name=model_name)\n",
        "    print(f\"\\n‚úì Model loaded successfully!\")\n",
        "    print(f\"  Encoder: {model.encoder.__class__.__name__}\")\n",
        "    print(f\"  Decoder: {model.decoder.__class__.__name__}\")\n",
        "    print(f\"  Joint: {model.joint.__class__.__name__}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error loading model: {e}\")\n",
        "    print(\"\\nTrying alternative loading method...\")\n",
        "    model = nemo_asr.models.ASRModel.from_pretrained(model_name=model_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Configure Model for Fine-Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update model configuration\n",
        "cfg = model.cfg\n",
        "\n",
        "with open_dict(cfg):\n",
        "    # ==================\n",
        "    # Training Data\n",
        "    # ==================\n",
        "    cfg.train_ds.manifest_filepath = DATA_CONFIG.train_manifest\n",
        "    cfg.train_ds.batch_size = DATA_CONFIG.train_batch_size\n",
        "    cfg.train_ds.num_workers = DATA_CONFIG.num_workers\n",
        "    cfg.train_ds.sample_rate = DATA_CONFIG.sample_rate\n",
        "    cfg.train_ds.max_duration = DATA_CONFIG.max_duration\n",
        "    cfg.train_ds.min_duration = DATA_CONFIG.min_duration\n",
        "    cfg.train_ds.shuffle = True\n",
        "    cfg.train_ds.pin_memory = True\n",
        "    \n",
        "    # ==================\n",
        "    # Validation Data\n",
        "    # ==================\n",
        "    cfg.validation_ds.manifest_filepath = DATA_CONFIG.val_manifest\n",
        "    cfg.validation_ds.batch_size = DATA_CONFIG.val_batch_size\n",
        "    cfg.validation_ds.num_workers = DATA_CONFIG.num_workers\n",
        "    cfg.validation_ds.sample_rate = DATA_CONFIG.sample_rate\n",
        "    cfg.validation_ds.shuffle = False\n",
        "    cfg.validation_ds.pin_memory = True\n",
        "    \n",
        "    # ==================\n",
        "    # Optimizer\n",
        "    # ==================\n",
        "    cfg.optim.name = TRAINING_CONFIG.optimizer\n",
        "    cfg.optim.lr = TRAINING_CONFIG.learning_rate\n",
        "    cfg.optim.weight_decay = TRAINING_CONFIG.weight_decay\n",
        "    cfg.optim.betas = [0.9, 0.98]\n",
        "    \n",
        "    # ==================\n",
        "    # Scheduler\n",
        "    # ==================\n",
        "    cfg.optim.sched.name = TRAINING_CONFIG.scheduler\n",
        "    cfg.optim.sched.warmup_steps = TRAINING_CONFIG.warmup_steps\n",
        "    cfg.optim.sched.min_lr = TRAINING_CONFIG.min_lr\n",
        "    \n",
        "    # ==================\n",
        "    # Spec Augmentation\n",
        "    # ==================\n",
        "    if hasattr(cfg, 'spec_augment') and DATA_CONFIG.enable_spec_augment:\n",
        "        cfg.spec_augment.freq_masks = DATA_CONFIG.freq_masks\n",
        "        cfg.spec_augment.time_masks = DATA_CONFIG.time_masks\n",
        "        cfg.spec_augment.freq_width = DATA_CONFIG.freq_width\n",
        "        cfg.spec_augment.time_width = DATA_CONFIG.time_width\n",
        "\n",
        "print(\"‚úì Model configuration updated\")\n",
        "\n",
        "# Freeze encoder if specified\n",
        "if TRAINING_CONFIG.freeze_encoder:\n",
        "    print(\"üßä Freezing encoder layers\")\n",
        "    model.encoder.freeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup data loaders\n",
        "print(\"Setting up data loaders...\")\n",
        "model.setup_training_data(cfg.train_ds)\n",
        "model.setup_validation_data(cfg.validation_ds)\n",
        "print(\"‚úì Data loaders ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Setup Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pytorch_lightning.callbacks import (\n",
        "    ModelCheckpoint,\n",
        "    EarlyStopping,\n",
        "    LearningRateMonitor\n",
        ")\n",
        "\n",
        "# Create output directory\n",
        "Path(TRAINING_CONFIG.output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    LearningRateMonitor(logging_interval='step'),\n",
        "]\n",
        "\n",
        "# Trainer\n",
        "trainer = pl.Trainer(\n",
        "    devices=TRAINING_CONFIG.devices,\n",
        "    accelerator=TRAINING_CONFIG.accelerator,\n",
        "    max_epochs=TRAINING_CONFIG.max_epochs,\n",
        "    precision=TRAINING_CONFIG.precision,\n",
        "    accumulate_grad_batches=TRAINING_CONFIG.accumulate_grad_batches,\n",
        "    gradient_clip_val=TRAINING_CONFIG.grad_clip,\n",
        "    log_every_n_steps=TRAINING_CONFIG.log_every_n_steps,\n",
        "    enable_checkpointing=True,\n",
        "    callbacks=callbacks,\n",
        "    default_root_dir=TRAINING_CONFIG.output_dir,\n",
        ")\n",
        "\n",
        "# NeMo Experiment Manager\n",
        "exp_manager_config = {\n",
        "    'exp_dir': TRAINING_CONFIG.output_dir,\n",
        "    'name': TRAINING_CONFIG.exp_name,\n",
        "    'checkpoint_callback_params': {\n",
        "        'monitor': 'val_wer',\n",
        "        'mode': 'min',\n",
        "        'save_top_k': TRAINING_CONFIG.save_top_k,\n",
        "        'save_last': True,\n",
        "    },\n",
        "    'create_tensorboard_logger': True,\n",
        "    'create_wandb_logger': False,\n",
        "}\n",
        "\n",
        "# Add early stopping\n",
        "if TRAINING_CONFIG.early_stop_patience > 0:\n",
        "    exp_manager_config['early_stopping_callback_params'] = {\n",
        "        'monitor': 'val_wer',\n",
        "        'patience': TRAINING_CONFIG.early_stop_patience,\n",
        "        'min_delta': 0.001,\n",
        "        'mode': 'min',\n",
        "    }\n",
        "\n",
        "exp_manager(trainer, exp_manager_config)\n",
        "\n",
        "print(\"‚úì Trainer configured\")\n",
        "print(f\"  Output: {TRAINING_CONFIG.output_dir}\")\n",
        "print(f\"  Epochs: {TRAINING_CONFIG.max_epochs}\")\n",
        "print(f\"  Precision: {TRAINING_CONFIG.precision}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ STARTING FINE-TUNING\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nModel: {TRAINING_CONFIG.pretrained_model}\")\n",
        "print(f\"Epochs: {TRAINING_CONFIG.max_epochs}\")\n",
        "print(f\"Learning rate: {TRAINING_CONFIG.learning_rate}\")\n",
        "print(f\"Batch size: {DATA_CONFIG.train_batch_size}\")\n",
        "print(f\"Gradient accumulation: {TRAINING_CONFIG.accumulate_grad_batches}\")\n",
        "print(f\"Effective batch size: {DATA_CONFIG.train_batch_size * TRAINING_CONFIG.accumulate_grad_batches}\")\n",
        "print(\"\\nTraining...\\n\")\n",
        "\n",
        "trainer.fit(\n",
        "    model,\n",
        "    ckpt_path=TRAINING_CONFIG.resume_from_checkpoint\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úì Training complete!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save final model\n",
        "final_model_path = Path(TRAINING_CONFIG.output_dir) / \"final_model.nemo\"\n",
        "model.save_to(str(final_model_path))\n",
        "print(f\"\\nüíæ Model saved to: {final_model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "if DATA_CONFIG.test_manifest and Path(DATA_CONFIG.test_manifest).exists():\n",
        "    print(\"Evaluating on test set...\")\n",
        "    \n",
        "    with open_dict(model.cfg):\n",
        "        model.cfg.test_ds.manifest_filepath = DATA_CONFIG.test_manifest\n",
        "        model.cfg.test_ds.batch_size = DATA_CONFIG.val_batch_size\n",
        "        model.cfg.test_ds.num_workers = DATA_CONFIG.num_workers\n",
        "    \n",
        "    model.setup_test_data(model.cfg.test_ds)\n",
        "    test_results = trainer.test(model)\n",
        "    \n",
        "    print(f\"\\nüìä Test Results: {test_results}\")\n",
        "else:\n",
        "    print(\"No test manifest found, skipping evaluation.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_finetuned_model(model_path: str):\n",
        "    \"\"\"Load fine-tuned model for inference.\"\"\"\n",
        "    loaded_model = nemo_asr.models.EncDecRNNTBPEModel.restore_from(model_path)\n",
        "    loaded_model.eval()\n",
        "    if torch.cuda.is_available():\n",
        "        loaded_model = loaded_model.cuda()\n",
        "    return loaded_model\n",
        "\n",
        "\n",
        "def transcribe(model_to_use, audio_paths: Union[str, List[str]], batch_size: int = 4):\n",
        "    \"\"\"Transcribe audio files.\"\"\"\n",
        "    if isinstance(audio_paths, str):\n",
        "        audio_paths = [audio_paths]\n",
        "    return model_to_use.transcribe(paths2audio_files=audio_paths, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Load and use fine-tuned model\n",
        "# Uncomment to test\n",
        "\n",
        "# model_path = \"./outputs/parakeet-rnnt-finetuned/final_model.nemo\"\n",
        "# finetuned_model = load_finetuned_model(model_path)\n",
        "\n",
        "# # Transcribe audio files\n",
        "# audio_files = [\n",
        "#     \"path/to/audio1.wav\",\n",
        "#     \"path/to/audio2.wav\",\n",
        "# ]\n",
        "# transcriptions = transcribe(finetuned_model, audio_files)\n",
        "\n",
        "# for audio, text in zip(audio_files, transcriptions):\n",
        "#     print(f\"{Path(audio).name}: {text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Tips & Best Practices\n",
        "\n",
        "### Dataset Size Recommendations\n",
        "\n",
        "| Dataset Size | Learning Rate | Freeze Encoder | Epochs |\n",
        "|--------------|--------------|----------------|--------|\n",
        "| < 10 hours | 5e-5 | Yes | 50-100 |\n",
        "| 10-100 hours | 1e-4 | First 5 epochs | 30-50 |\n",
        "| > 100 hours | 3e-4 | No | 20-30 |\n",
        "\n",
        "### Memory Optimization\n",
        "\n",
        "If you run out of GPU memory:\n",
        "1. Reduce `batch_size`\n",
        "2. Increase `accumulate_grad_batches`\n",
        "3. Reduce `max_duration`\n",
        "4. Use `precision=\"16-mixed\"`\n",
        "\n",
        "### Multilingual Fine-Tuning\n",
        "\n",
        "For multilingual datasets:\n",
        "1. Include `lang` field in manifest entries\n",
        "2. Balance samples across languages\n",
        "3. Consider language-specific augmentation\n",
        "\n",
        "### Manifest Format\n",
        "\n",
        "```json\n",
        "{\"audio_filepath\": \"/path/audio.wav\", \"text\": \"hello world\", \"duration\": 2.5, \"lang\": \"en\"}\n",
        "{\"audio_filepath\": \"/path/audio2.wav\", \"text\": \"bonjour monde\", \"duration\": 3.1, \"lang\": \"fr\"}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ Fine-tuning pipeline complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nOutput directory: {TRAINING_CONFIG.output_dir}\")\n",
        "print(f\"Model file: {TRAINING_CONFIG.output_dir}/final_model.nemo\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"  1. Review TensorBoard logs for training curves\")\n",
        "print(\"  2. Test model on your evaluation data\")\n",
        "print(\"  3. Export model for deployment\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
